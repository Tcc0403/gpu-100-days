{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae381edc",
   "metadata": {},
   "source": [
    "# Grayscale\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/Tcc0403/gpu-100-days/blob/main/day003/grayscale.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4870252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e090310",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103594a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import triton\n",
    "import triton.language as tl\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e0d55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b6defe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "!wget \"https://raw.githubusercontent.com/Tcc0403/gpu-100-days/refs/heads/main/day003/img/img0.jpg\"\n",
    "!mv \"img0.jpg\" \"img/img0.jpg\"\n",
    "img0 = io.decode_image('img/img0.jpg').cuda()\n",
    "print(img0.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d63ac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(x, figsize=(8,6), **kwargs):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.axis('off')\n",
    "    if len(x.shape)==3: x = x.permute(1,2,0)  # CHW -> HWC\n",
    "    plt.imshow(x.cpu(), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7fe29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(img0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1871a5c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b665eda1",
   "metadata": {},
   "source": [
    "## Write a reference kernel as baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce4bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ref_grayscale(x):\n",
    "    c,h,w = x.shape\n",
    "    R = x[0, :, :]\n",
    "    G = x[1, :, :]\n",
    "    B = x[2, :, :]\n",
    "    \n",
    "    res = 0.2989 * R + 0.5870 * G + 0.1140 * B\n",
    "    return res.view(h,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185f88de",
   "metadata": {},
   "outputs": [],
   "source": [
    "img0_gray = ref_grayscale(img0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7d3fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(img0_gray, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e8674e",
   "metadata": {},
   "source": [
    "## Write Triton kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c010ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def grayscale_element_kernel(\n",
    "    x_ptr, \n",
    "    output_ptr, \n",
    "    n_elements, # H * W\n",
    "    BLOCK_SIZE: tl.constexpr\n",
    "):\n",
    "    pid = tl.program_id(0)\n",
    "\n",
    "    r_ptr_start = x_ptr \n",
    "    g_ptr_start = x_ptr + n_elements\n",
    "    b_ptr_start = x_ptr + 2 * n_elements \n",
    "\n",
    "    block_offset = BLOCK_SIZE * pid\n",
    "    r_block_start = r_ptr_start + block_offset\n",
    "    g_block_start = g_ptr_start + block_offset\n",
    "    b_block_start = b_ptr_start + block_offset\n",
    "\n",
    "    output_ptr = output_ptr + BLOCK_SIZE * pid\n",
    "    \n",
    "    offsets = tl.arange(0, BLOCK_SIZE)\n",
    "    r_ptrs = r_block_start + offsets\n",
    "    g_ptrs = g_block_start + offsets\n",
    "    b_ptrs = b_block_start + offsets\n",
    "\n",
    "    mask = block_offset + offsets < n_elements\n",
    "    r = tl.load(r_ptrs, mask=mask)\n",
    "    g = tl.load(g_ptrs, mask=mask)\n",
    "    b = tl.load(b_ptrs, mask=mask)\n",
    "\n",
    "    output = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    tl.store(output_ptr + offsets, output, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dacf244",
   "metadata": {},
   "source": [
    "## Helper function to allocate tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115e6846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale_element(x):\n",
    "    C, H, W = x.shape\n",
    "    output = torch.empty((H, W), dtype=x.dtype, device=x.device)\n",
    "    n_elements = H * W\n",
    "    BLOCK_SIZE = 1024\n",
    "\n",
    "    grid = (triton.cdiv(x.numel(), BLOCK_SIZE),)\n",
    "    grayscale_element_kernel[grid](x, output, n_elements, BLOCK_SIZE=BLOCK_SIZE)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8c880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img0_gray_v0 = grayscale_element(img0)\n",
    "show_img(img0_gray_v0, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efbffbf",
   "metadata": {},
   "source": [
    "### Why incorrect?  **Contiguous!**\n",
    "\n",
    "https://ezyang.github.io/stride-visualizer/index.html\n",
    "\n",
    "https://blog.ezyang.com/2019/05/pytorch-internals/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9e321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img0.shape)\n",
    "print(img0.stride())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d220df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img0.contiguous().stride())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5ec147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale_element_ensure_contiguous(x):\n",
    "    C, H, W = x.shape\n",
    "    output = torch.empty((H, W), dtype=x.dtype, device=x.device)\n",
    "    n_elements = H * W\n",
    "    BLOCK_SIZE = 1024\n",
    "\n",
    "    # Ensure Contiguous\n",
    "    x = x.contiguous()\n",
    "\n",
    "    # grid = (triton.cdiv(x.numel(), BLOCK_SIZE),)\n",
    "    grid = lambda meta: (triton.cdiv(x.numel(), meta['BLOCK_SIZE']), )\n",
    "    grayscale_element_kernel[grid](x, output, n_elements, BLOCK_SIZE)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017d0b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "img0_gray_v1 = grayscale_element_ensure_contiguous(img0)\n",
    "show_img(img0_gray_v1, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eadf56",
   "metadata": {},
   "source": [
    "## Another Triton Kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e67b6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def grayscale_2d_kernel(\n",
    "    x_ptr, \n",
    "    output_ptr, \n",
    "    h,\n",
    "    w,\n",
    "    BLOCK_H: tl.constexpr,\n",
    "    BLOCK_W: tl.constexpr,\n",
    "):\n",
    "    pid_h = tl.program_id(0)\n",
    "    pid_w = tl.program_id(1)\n",
    "\n",
    "    r_ptr_start = x_ptr \n",
    "    g_ptr_start = x_ptr + h * w\n",
    "    b_ptr_start = x_ptr + 2 * h * w\n",
    "\n",
    "    # Calculate offsets\n",
    "    offsets_h = pid_h * BLOCK_H + tl.arange(0, BLOCK_H)  # 1d\n",
    "    offsets_w = pid_w * BLOCK_W + tl.arange(0, BLOCK_W)  # 1d\n",
    "\n",
    "    block_offsets = w * offsets_h[:, None] + offsets_w[None, :]  # 2d\n",
    "\n",
    "    r_ptrs = r_ptr_start + block_offsets\n",
    "    g_ptrs = g_ptr_start + block_offsets\n",
    "    b_ptrs = b_ptr_start + block_offsets\n",
    "    \n",
    "\n",
    "    # Calculate mask\n",
    "    mask_h = offsets_h < h   # 1d\n",
    "    mask_w = offsets_w < w   # 1d\n",
    "    mask = mask_h[:, None] & mask_w[None, :]  # 2d\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    r = tl.load(r_ptrs, mask=mask)\n",
    "    g = tl.load(g_ptrs, mask=mask)\n",
    "    b = tl.load(b_ptrs, mask=mask)\n",
    "\n",
    "    output = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    tl.store(output_ptr + block_offsets, output, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb7dba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale_2d_ensure_contiguous(x):\n",
    "    C, H, W = x.shape\n",
    "    output = torch.empty((H, W), dtype=x.dtype, device=x.device)\n",
    "    BLOCK_H = 32\n",
    "    BLOCK_W = 32\n",
    "\n",
    "    # Ensure Contiguous\n",
    "    x = x.contiguous()\n",
    "\n",
    "    # grid = (triton.cdiv(H, BLOCK_H), triton.cdiv(W, BLOCK_W))\n",
    "    grid = lambda meta: (triton.cdiv(H, meta['BLOCK_H']), triton.cdiv(W, meta['BLOCK_W']))\n",
    "    grayscale_2d_kernel[grid](x, output, H, W, BLOCK_H, BLOCK_W)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2357fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img0_gray_v2 = grayscale_2d_ensure_contiguous(img0)\n",
    "show_img(img0_gray_v2, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a331f17a",
   "metadata": {},
   "source": [
    "## Congrats! Try more images!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d43721",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67543700",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"https://raw.githubusercontent.com/Tcc0403/gpu-100-days/refs/heads/main/day003/img/img1.jpg\" \n",
    "!mv \"img1.jpg\" \"img/img1.jpg\"\n",
    "img1 = io.decode_image('img/img1.jpg').cuda()\n",
    "img1_gray_v1 = grayscale_element_ensure_contiguous(img1)\n",
    "img1_gray_v2 = grayscale_2d_ensure_contiguous(img1)\n",
    "\n",
    "show_img(img1_gray_v1, cmap=\"gray\")\n",
    "show_img(img1_gray_v2, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee42975",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"https://raw.githubusercontent.com/Tcc0403/gpu-100-days/refs/heads/main/day003/img/img2.jpg\" \n",
    "!mv \"img2.jpg\" \"img/img2.jpg\"\n",
    "img2 = io.decode_image('img/img2.jpg').cuda()\n",
    "img2_gray_v1 = grayscale_element_ensure_contiguous(img2)\n",
    "img2_gray_v2 = grayscale_2d_ensure_contiguous(img2)\n",
    "\n",
    "show_img(img2_gray_v1, cmap=\"gray\")\n",
    "show_img(img2_gray_v2, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d499b0f6",
   "metadata": {},
   "source": [
    "## Test the correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5d61c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_1d(C, H, W, with_transpose=False):\n",
    "\n",
    "    size = (C, H, W) if not with_transpose else (H, W, C)\n",
    "\n",
    "    x = torch.randn(size, device=DEVICE)\n",
    "    \n",
    "    if with_transpose:\n",
    "        x = x.permute(2, 0, 1)  # H, W, C -> C, H, W\n",
    "\n",
    "    output_ref = ref_grayscale(x)\n",
    "    output_triton = grayscale_element_ensure_contiguous(x)    \n",
    "\n",
    "    torch.testing.assert_close(output_triton, output_ref)\n",
    "    print(\"✅ Triton kernel is correct!\")\n",
    "\n",
    "C, H, W = 3, 2025, 4096\n",
    "test_1d(C, H, W)\n",
    "test_1d(C, H, W, with_transpose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ec9369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_2d(C, H, W, with_transpose=False):\n",
    "\n",
    "    size = (C, H, W) if not with_transpose else (H, W, C)\n",
    "\n",
    "    x = torch.randn(size, device=DEVICE)\n",
    "    \n",
    "    if with_transpose:\n",
    "        x = x.permute(2, 0, 1)  # H, W, C -> C, H, W\n",
    "\n",
    "    output_ref = ref_grayscale(x)\n",
    "    output_triton = grayscale_2d_ensure_contiguous(x)    \n",
    "\n",
    "    torch.testing.assert_close(output_triton, output_ref)\n",
    "    print(\"✅ Triton kernel is correct!\")\n",
    "\n",
    "\n",
    "C, H, W = 3, 2025, 4096\n",
    "test_2d(C, H, W)\n",
    "test_2d(C, H, W, with_transpose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621ab898",
   "metadata": {},
   "source": [
    "## Benchmark with `triton.testing.do_bench`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3dce90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "@triton.testing.perf_report(\n",
    "    triton.testing.Benchmark(\n",
    "        x_names=['H'],  # Argument names to use as an x-axis for the plot.\n",
    "        x_vals=[2 ** i for i in range(3, 15, 1)],  # Different possible values for `x_name`.\n",
    "        x_log=True,  # x axis is logarithmic.\n",
    "        line_arg='provider',  # Argument name whose value corresponds to a different line in the plot.\n",
    "        line_vals=['triton_2d', 'triton_1d', 'torch'],  # Possible values for `line_arg`.\n",
    "        line_names=['triton_2d', 'triton_1d', 'torch'],  # Possible values for `line_arg`.\n",
    "        styles=[('red', '-'), ('blue', '-'), ('green', '-')],  # Line styles.\n",
    "        ylabel='GB/s',  # Label name for the y-axis.\n",
    "        plot_name='grayscale-performance',  # Name for the plot. Used also as a file name for saving the plot.\n",
    "        args={},  # Values for function arguments not in `x_names` and `y_name`.\n",
    "    ))\n",
    "def benchmark_gbps(H, provider):\n",
    "    \n",
    "\n",
    "    W = H  \n",
    "    size = (C, H, W) \n",
    "\n",
    "    x = torch.randn(size, device=DEVICE)\n",
    "\n",
    "\n",
    "    x = torch.rand(size, device=DEVICE, dtype=torch.float32)\n",
    "    quantiles = [0.5, 0.2, 0.8]\n",
    "    if provider == 'torch':\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: ref_grayscale(x), quantiles=quantiles)\n",
    "    if provider == 'triton_1d':\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: grayscale_element_ensure_contiguous(x), quantiles=quantiles)\n",
    "    if provider == 'triton_2d':\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: grayscale_2d_ensure_contiguous(x), quantiles=quantiles)\n",
    "    gbps = lambda ms: 4 * H * W * x.element_size() * 1e-9 / (ms * 1e-3)\n",
    "    return gbps(ms), gbps(max_ms), gbps(min_ms)\n",
    "\n",
    "\n",
    "benchmark_gbps.run(print_data=True, show_plots=True, save_path=os.path.abspath(\"../benchmark\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320e4b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.testing.perf_report(\n",
    "    triton.testing.Benchmark(\n",
    "        x_names=['H'],  # Argument names to use as an x-axis for the plot.\n",
    "        x_vals=[2 ** i for i in range(3, 15, 1)],  # Different possible values for `x_name`.\n",
    "        x_log=True,  # x axis is logarithmic.\n",
    "        line_arg='provider',  # Argument name whose value corresponds to a different line in the plot.\n",
    "        line_vals=['triton_2d', 'triton_1d', 'torch'],  # Possible values for `line_arg`.\n",
    "        line_names=['triton_2d', 'triton_1d', 'torch'],  # Possible values for `line_arg`.\n",
    "        styles=[('red', '-'), ('blue', '-'), ('green', '-')],  # Line styles.\n",
    "        ylabel='GFLOPs/s',  # Label name for the y-axis.\n",
    "        plot_name='grayscale-performance',  # Name for the plot. Used also as a file name for saving the plot.\n",
    "        args={},  # Values for function arguments not in `x_names` and `y_name`.\n",
    "    ))\n",
    "def benchmark_gflops(H, provider):\n",
    "    \n",
    "\n",
    "    W = H  \n",
    "    size = (C, H, W) \n",
    "\n",
    "    x = torch.randn(size, device=DEVICE)\n",
    "\n",
    "\n",
    "    x = torch.rand(size, device=DEVICE, dtype=torch.float32)\n",
    "    quantiles = [0.5, 0.2, 0.8]\n",
    "    if provider == 'torch':\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: ref_grayscale(x), quantiles=quantiles)\n",
    "    if provider == 'triton_1d':\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: grayscale_element_ensure_contiguous(x), quantiles=quantiles)\n",
    "    if provider == 'triton_2d':\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: grayscale_2d_ensure_contiguous(x), quantiles=quantiles)\n",
    "    # 3 mulitplication and 3 addition\n",
    "    gflops = lambda ms: 6 * H * W * 1e-9 / (ms * 1e-3)\n",
    "    return gflops(ms), gflops(max_ms), gflops(min_ms)\n",
    "\n",
    "\n",
    "benchmark_gflops.run(print_data=True, show_plots=True, save_path=os.path.abspath(\"../benchmark\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5154ea3",
   "metadata": {},
   "source": [
    "## Autotune\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bb6cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.autotune(\n",
    "        configs=[\n",
    "            triton.Config({'BLOCK_H': 32, 'BLOCK_W': 32}, num_warps=2),\n",
    "            triton.Config({'BLOCK_H': 64, 'BLOCK_W': 32}, num_warps=2),\n",
    "            triton.Config({'BLOCK_H': 32, 'BLOCK_W': 64}, num_warps=4),\n",
    "            triton.Config({'BLOCK_H': 64, 'BLOCK_W': 64}, num_warps=4),\n",
    "            triton.Config({'BLOCK_H': 128, 'BLOCK_W': 64}, num_warps=8),\n",
    "            triton.Config({'BLOCK_H': 64, 'BLOCK_W': 128}, num_warps=8),\n",
    "            triton.Config({'BLOCK_H': 128, 'BLOCK_W': 128}, num_warps=8),\n",
    "        ],\n",
    "        key=['h', 'w']\n",
    ")\n",
    "@triton.jit\n",
    "def grayscale_2d_autotuned_kernel(\n",
    "    x_ptr, \n",
    "    output_ptr, \n",
    "    h,\n",
    "    w,\n",
    "    BLOCK_H: tl.constexpr,\n",
    "    BLOCK_W: tl.constexpr,\n",
    "):\n",
    "    pid_h = tl.program_id(0)\n",
    "    pid_w = tl.program_id(1)\n",
    "\n",
    "    r_ptr_start = x_ptr \n",
    "    g_ptr_start = x_ptr + h * w\n",
    "    b_ptr_start = x_ptr + 2 * h * w\n",
    "\n",
    "    # Calculate offsets\n",
    "    offsets_h = pid_h * BLOCK_H + tl.arange(0, BLOCK_H)  # 1d\n",
    "    offsets_w = pid_w * BLOCK_W + tl.arange(0, BLOCK_W)  # 1d\n",
    "\n",
    "    block_offsets = w * offsets_h[:, None] + offsets_w[None, :]  # 2d\n",
    "\n",
    "    r_ptrs = r_ptr_start + block_offsets\n",
    "    g_ptrs = g_ptr_start + block_offsets\n",
    "    b_ptrs = b_ptr_start + block_offsets\n",
    "    \n",
    "\n",
    "    # Calculate mask\n",
    "    mask_h = offsets_h < h   # 1d\n",
    "    mask_w = offsets_w < w   # 1d\n",
    "    mask = mask_h[:, None] & mask_w[None, :]  # 2d\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    r = tl.load(r_ptrs, mask=mask)\n",
    "    g = tl.load(g_ptrs, mask=mask)\n",
    "    b = tl.load(b_ptrs, mask=mask)\n",
    "\n",
    "    output = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    tl.store(output_ptr + block_offsets, output, mask=mask)\n",
    "\n",
    "\n",
    "def grayscale_2d_autotuned(x):\n",
    "    C, H, W = x.shape\n",
    "    output = torch.empty((H, W), dtype=x.dtype, device=x.device)\n",
    "    # BLOCK_H = 32\n",
    "    # BLOCK_W = 32\n",
    "\n",
    "    # Ensure Contiguous\n",
    "    x = x.contiguous()\n",
    "\n",
    "    # grid = (triton.cdiv(H, BLOCK_H), triton.cdiv(W, BLOCK_W))\n",
    "    grid = lambda meta: (triton.cdiv(H, meta['BLOCK_H']), triton.cdiv(W, meta['BLOCK_W']))\n",
    "    grayscale_2d_autotuned_kernel[grid](x, output, H, W)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd754278",
   "metadata": {},
   "source": [
    "`TRITON_PRINT_AUTOTUNING=1` prints out the best autotuning config and total time spent for each kernel after autotuning is complete.\n",
    "\n",
    "`TRITON_ALWAYS_COMPILE=1` forces to compile kernels regardless of cache hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bcd1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRITON_PRINT_AUTOTUNING=1\n",
    "# TRITON_ALWAYS_COMPILE=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aef7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.testing.perf_report(\n",
    "    triton.testing.Benchmark(\n",
    "        x_names=['H'],  # Argument names to use as an x-axis for the plot.\n",
    "        x_vals=[2 ** i for i in range(3, 15, 1)],  # Different possible values for `x_name`.\n",
    "        x_log=True,  # x axis is logarithmic.\n",
    "        line_arg='provider',  # Argument name whose value corresponds to a different line in the plot.\n",
    "        line_vals=['triton_2d', 'triton_1d', 'triton_2d_autotuned'],  # Possible values for `line_arg`.\n",
    "        line_names=['triton_2d', 'triton_1d', 'triton_2d_autotuned'],  # Possible values for `line_arg`.\n",
    "        styles=[('red', '-'), ('blue', '-'), ('green', '-')],  # Line styles.\n",
    "        ylabel='GB/s',  # Label name for the y-axis.\n",
    "        plot_name='grayscale-performance',  # Name for the plot. Used also as a file name for saving the plot.\n",
    "        args={},  # Values for function arguments not in `x_names` and `y_name`.\n",
    "    ))\n",
    "def benchmark(H, provider):\n",
    "    \n",
    "\n",
    "    W = H  \n",
    "    size = (C, H, W) \n",
    "\n",
    "    x = torch.randn(size, device=DEVICE)\n",
    "\n",
    "\n",
    "    x = torch.rand(size, device=DEVICE, dtype=torch.float32)\n",
    "    quantiles = [0.5, 0.2, 0.8]\n",
    "    if provider == 'triton_1d':\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: grayscale_element_ensure_contiguous(x), quantiles=quantiles)\n",
    "    if provider == 'triton_2d':\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: grayscale_2d_ensure_contiguous(x), quantiles=quantiles)\n",
    "    if provider == 'triton_2d_autotuned':\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: grayscale_2d_autotuned(x), quantiles=quantiles)\n",
    "    gbps = lambda ms: 4 * H * W * x.element_size() * 1e-9 / (ms * 1e-3)\n",
    "    return gbps(ms), gbps(max_ms), gbps(min_ms)\n",
    "\n",
    "\n",
    "benchmark.run(print_data=True, show_plots=True, save_path=os.path.abspath(\"../benchmark\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
